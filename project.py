import streamlit as st
import pandas as pd
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
import os

# --- Veri Ä°ÅŸleme Fonksiyonu ---
def preprocess_nba_data(file_path):
    try:
        df = pd.read_csv(file_path, delimiter=';')
    except FileNotFoundError:
        st.error(f"Hata: '{file_path}' dosyasÄ± bulunamadÄ±. LÃ¼tfen dosyanÄ±n doÄŸru yolda olduÄŸundan emin olun.")
        return None, None
    except Exception as e:
        st.error(f"Dosya okunurken bir hata oluÅŸtu: {e}")
        return None, None

    documents = []
    df.columns = df.columns.str.strip()
    
    for index, row in df.iterrows():
        try:
            text = f"{row['Player']} ({row['Tm']}), {row['Data']} tarihinde {row['Opp']} takÄ±mÄ±na karÅŸÄ± oynanan maÃ§ta " \
                   f"{row['MP']} dakika sÃ¼re aldÄ±. MaÃ§Ä± {row['PTS']} sayÄ±, {row['TRB']} ribaund, " \
                   f"{row['AST']} asist, {row['STL']} top Ã§alma ve {row['BLK']} blok ile tamamladÄ±. " \
                   f"Saha iÃ§i isabet oranÄ± %{float(row['FG%'])*100:.1f} idi."
            documents.append(text)
        except (ValueError, KeyError, TypeError) as e:
            continue
    return df, documents

# --- LangChain ve FAISS ile VektÃ¶r VeritabanÄ± OluÅŸturma ---
@st.cache_resource
def create_vector_store(documents):
    try:
        # Ãœcretsiz lokal embedding kullan (Gemini quota sorunu yok)
        from langchain_community.embeddings import HuggingFaceEmbeddings
        
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        vector_store = FAISS.from_texts(documents, embedding=embeddings)
        return vector_store
    except Exception as e:
        st.error(f"VektÃ¶r veritabanÄ± oluÅŸturulurken hata oluÅŸtu: {e}")
        return None

# --- Gemini ve LangChain ile Cevap Ãœretme ---
def get_conversational_chain(api_key):
    prompt_template = """
    Sana verilen baÄŸlamÄ± kullanarak soruyu olabildiÄŸince detaylÄ± bir ÅŸekilde TÃ¼rkÃ§e yanÄ±tla. 
    EÄŸer cevabÄ± baÄŸlamda bulamazsan, "ÃœzgÃ¼nÃ¼m, bu bilgiye sahip deÄŸilim." de. Kendi bilgini kullanma.\n\n
    BaÄŸlam:\n {context}?\n
    Soru: \n{question}\n

    Cevap:
    """
    model = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro", 
        temperature=0.3,
        google_api_key=api_key,
        convert_system_message_to_human=True
    )
    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
    return chain

# --- Streamlit ArayÃ¼zÃ¼ ---
st.set_page_config(page_title="ğŸ€ NBA Fantezi AsistanÄ±", layout="wide")
st.title("ğŸ€ NBA Fantezi AsistanÄ± Chatbot'u")
st.write("Oyuncu istatistikleri hakkÄ±nda sorularÄ±nÄ±zÄ± sorun!")

# API AnahtarÄ±nÄ± kullanÄ±cÄ±dan al
api_key = st.sidebar.text_input("Google API AnahtarÄ±nÄ±zÄ± Girin:", type="password")

if api_key:
    # Veriyi yÃ¼kle ve iÅŸle
    FILE_PATH = 'nba_fantasy_dataset.csv'
    df, documents = preprocess_nba_data(FILE_PATH)

    if documents:
        # VektÃ¶r veritabanÄ±nÄ± oluÅŸtur
        with st.spinner("VektÃ¶r veritabanÄ± oluÅŸturuluyor... (Ä°lk seferde biraz zaman alabilir)"):
            vector_store = create_vector_store(documents)
        
        if vector_store:
            st.success("âœ… Sistem hazÄ±r! SorularÄ±nÄ±zÄ± sorabilirsiniz.")
            
            # KullanÄ±cÄ±dan soru al
            user_question = st.text_input("Sorunuzu yazÄ±n:", placeholder="Ã–rnek: 'Jayson Tatum en son maÃ§Ä±nda kaÃ§ sayÄ± attÄ±?'")

            if st.button("ğŸ” Soru Sor"):
                if user_question:
                    with st.spinner("Cevap aranÄ±yor..."):
                        try:
                            # Soruyu yanÄ±tlama
                            docs = vector_store.similarity_search(user_question, k=3)
                            chain = get_conversational_chain(api_key)
                            response = chain(
                                {"input_documents": docs, "question": user_question}, 
                                return_only_outputs=True
                            )
                            
                            st.write("### ğŸ’¬ Cevap:")
                            st.write(response["output_text"])
                            
                            # Kaynak gÃ¶ster
                            with st.expander("ğŸ“š KullanÄ±lan Kaynaklar"):
                                for i, doc in enumerate(docs, 1):
                                    st.write(f"**Kaynak {i}:**")
                                    st.write(doc.page_content)
                                    st.divider()
                        except Exception as e:
                            st.error(f"Cevap Ã¼retilirken hata oluÅŸtu: {e}")
                else:
                    st.warning("âš ï¸ LÃ¼tfen bir soru girin.")
        else:
            st.error("VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±.")
    else:
        st.error("Veri dosyasÄ± yÃ¼klenemedi veya iÅŸlenemedi.")
else:
    st.sidebar.warning("âš ï¸ LÃ¼tfen baÅŸlamak iÃ§in Google API anahtarÄ±nÄ±zÄ± girin.")
    st.info("ğŸ‘ˆ Sol taraftaki alana API anahtarÄ±nÄ±zÄ± girin.")
