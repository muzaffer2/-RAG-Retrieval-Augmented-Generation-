# import torch
# print(torch.__version__)
# # 1. CUDA (GPU) kullanÄ±labilirliÄŸini kontrol et
# gpu_kullanilabilir = torch.cuda.is_available()
# print(f"CUDA (GPU) KullanÄ±labilir: {gpu_kullanilabilir}")

# if gpu_kullanilabilir:
#     # 2. KullanÄ±lan GPU sayÄ±sÄ±nÄ± ve adÄ±nÄ± al
#     gpu_sayisi = torch.cuda.device_count()
#     gpu_adi = torch.cuda.get_device_name(0) # Ä°lk GPU'nun adÄ±nÄ± alÄ±r
#     print(f"KullanÄ±lan GPU SayÄ±sÄ±: {gpu_sayisi}")
#     print(f"GPU AdÄ±: {gpu_adi}")

#     # 3. Basit bir tensÃ¶r iÅŸlemini GPU'ya taÅŸÄ±yarak test et
#     try:
#         x = torch.rand(5, 5).cuda()
#         y = torch.rand(5, 5).cuda()
#         z = x + y
#         print("GPU'da basit tensÃ¶r iÅŸlemi baÅŸarÄ±lÄ±.")
#     except Exception as e:
#         print(f"GPU iÅŸlemi baÅŸarÄ±sÄ±z: {e}")
# else:
#     print("GPU kullanÄ±lamÄ±yor, iÅŸlem CPU'da yÃ¼rÃ¼tÃ¼lecektir.")

import streamlit as st
import pandas as pd
import google.genai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.vectorstores import FAISS
from langchain.chains import load_qa_chain
from langchain.prompts import PromptTemplate
import os

# --- Veri Ä°ÅŸleme Fonksiyonu (Ã–nceki adÄ±mdan) ---
def preprocess_nba_data(file_path):
    try:
        df = pd.read_csv(file_path, delimiter=';')
    except FileNotFoundError:
        st.error(f"Hata: '{file_path}' dosyasÄ± bulunamadÄ±. LÃ¼tfen dosyanÄ±n doÄŸru yolda olduÄŸundan emin olun.")
        return None, None
    except Exception as e:
        st.error(f"Dosya okunurken bir hata oluÅŸtu: {e}")
        return None, None

    documents = []
    df.columns = df.columns.str.strip()
    
    for index, row in df.iterrows():
        try:
            text = f"{row['Player']} ({row['Tm']}), {row['Data']} tarihinde {row['Opp']} takÄ±mÄ±na karÅŸÄ± oynanan maÃ§ta " \
                   f"{row['MP']} dakika sÃ¼re aldÄ±. MaÃ§Ä± {row['PTS']} sayÄ±, {row['TRB']} ribaund, " \
                   f"{row['AST']} asist, {row['STL']} top Ã§alma ve {row['BLK']} blok ile tamamladÄ±. " \
                   f"Saha iÃ§i isabet oranÄ± %{float(row['FG%'])*100:.1f} idi."
            documents.append(text)
        except (ValueError, KeyError, TypeError) as e:
            # HatalÄ± satÄ±rlarÄ± atla ve bilgi ver
            # st.warning(f"Veri setindeki {index+1}. satÄ±r iÅŸlenirken bir hata oluÅŸtu ve atlandÄ±: {e}")
            continue
    return df, documents

# --- LangChain ve FAISS ile VektÃ¶r VeritabanÄ± OluÅŸturma ---
# @st.cache_resource
def create_vector_store(documents, api_key):
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
        vector_store = FAISS.from_texts(documents, embedding=embeddings)
        return vector_store
    except Exception as e:
        st.error(f"VektÃ¶r veritabanÄ± oluÅŸturulurken hata oluÅŸtu: {e}")
        return None

# --- Gemini ve LangChain ile Cevap Ãœretme ---
def get_conversational_chain():
    prompt_template = """
    Sana verilen baÄŸlamÄ± kullanarak soruyu olabildiÄŸince detaylÄ± bir ÅŸekilde TÃ¼rkÃ§e yanÄ±tla. 
    EÄŸer cevabÄ± baÄŸlamda bulamazsan, "ÃœzgÃ¼nÃ¼m, bu bilgiye sahip deÄŸilim." de. Kendi bilgini kullanma.\n\n
    BaÄŸlam:\n {context}?\n
    Soru: \n{question}\n

    Cevap:
    """
    model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3)
    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
    return chain

# --- Streamlit ArayÃ¼zÃ¼ ---
st.set_page_config(page_title="ğŸ€ NBA Fantezi AsistanÄ±", layout="wide")
st.title("ğŸ€ NBA Fantezi AsistanÄ± Chatbot'u")
st.write("Oyuncu istatistikleri hakkÄ±nda sorularÄ±nÄ±zÄ± sorun!")

# API AnahtarÄ±nÄ± kullanÄ±cÄ±dan al
api_key = st.sidebar.text_input("Google API AnahtarÄ±nÄ±zÄ± Girin:", type="password")

if api_key:
    # API anahtarÄ±nÄ± yapÄ±landÄ±r
    try:
        genai.configure(api_key=api_key)
    except Exception as e:
        st.error(f"API anahtarÄ± yapÄ±landÄ±rÄ±lÄ±rken bir hata oluÅŸtu: {e}")

    # Veriyi yÃ¼kle ve iÅŸle
    FILE_PATH = 'nba_fantasy_dataset.csv'
    df, documents = preprocess_nba_data(FILE_PATH)

    if documents:
        # VektÃ¶r veritabanÄ±nÄ± oluÅŸtur
        vector_store = create_vector_store(documents, api_key)
        
        if vector_store:
            # KullanÄ±cÄ±dan soru al
            user_question = st.text_input("Ã–rnek: 'Jayson Tatum en son maÃ§Ä±nda kaÃ§ sayÄ± attÄ±?'")

            if st.button("Soru Sor"):
                if user_question:
                    with st.spinner("Cevap aranÄ±yor..."):
                        # Soruyu yanÄ±tlama
                        docs = vector_store.similarity_search(user_question)
                        chain = get_conversational_chain()
                        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
                        
                        st.write("### Cevap:")
                        st.write(response["output_text"])
                else:
                    st.warning("LÃ¼tfen bir soru girin.")
else:
    st.sidebar.warning("LÃ¼tfen baÅŸlamak iÃ§in API anahtarÄ±nÄ±zÄ± girin.")
